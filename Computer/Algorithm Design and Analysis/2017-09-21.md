## 2017-09-21

- Asymptotic notations:
	- $f(n)=Ο(g(n))$: upper bound. $\exists\ k\gt 0, n_{0}>0$ such that $f(n)\leq k\cdot g(n)\ \forall\ n\gt n_{0}$
	- $f(n)=Θ(g(n))$: tight bound. $\exists\ k_{1}\gt 0, k_{2}\gt 0, n_{0}>0$ such that $k_{1}\cdot g(n)\leq f(n)\leq k_{2}\cdot g(n)\ \forall\ n\gt n_{0}$
	- $f(n)=Ω(g(n))$: lower bound. $\exists\ k\gt 0, n_{0}>0$ such that $k\cdot g(n)\leq f(n)\ \forall\ n\gt n_{0}$
	- $f(n)=ο(g(n))$: strict upper bound. $\forall\ k\gt 0\ \exists\ n_{0}>0$ such that $f(n)\lt k\cdot g(n)\ \forall\ n\gt n_{0}$
	- $f(n)=ω(g(n))$: strict lower bound. $\forall\ k\gt 0\ \exists\ n_{0}>0$ such that $k\cdot g(n)\lt f(n)\ \forall\ n\gt n_{0}$
- The property of $f(n)=Ο(g(n))$ holds after summation, multiplication, and power, but not logarithm and exponential.
- Average-case analysis requires the assumption about the probability distribution of problem instances.
- Time complexity and space complexity focus on the worst-case complexity.
- The (worst-case) time complexity of an algorithm is said to be $Θ(f(n))$ if $\exists\ f(n)$ s.t. $A$ runs in time $O(f(n))$ and $\Omega(f(n))$.
- Algorithm $A$ is _no worse than_ Algorithm $B$ in terms of worst-case time complexity if $\exists\ f(n)$ s.t. $A$ runs in time $O(f(n))$ and $B$ runs in time $\Omega(f(n))$.
- Algorithm $A$ is _(strictly) better than_ Algorithm $B$ in terms of worst-case time complexity if $\exists\ f(n)$ s.t. either
	- $A$ runs in time $O(f(n))$ and $B$ runs in time $\omega(f(n))$.
	- $A$ runs in time $o(f(n))$ and $B$ runs in time $\Omega(f(n))$.
- The (worst-case) time complexity of a problem is said to be $Θ(f(n))$ if _both_
	- The time complexity of the problem is $O(f(n))$, i.e. there exists an $O(f(n))$-time algorithm that solves the problem.
	- The time complexity of the problem is $\Omega(f(n))$, i.e. any algorithm that solves the problem requires $\Omega(f(n))$ time.
- Problem $P$ is _no harder than_ Problem $Q$ in terms of (worst-case) time complexity if $\exists\ f(n)$ s.t. the time complexity of $P$ is $O(f(n))$ and that of $Q$ is $\Omega(f(n))$.
- Problem $P$ is _(strictly) easier than_ Problem $Q$ in terms of (worst-case) time complexity if $\exists\ f(n)$ s.t. either
	- The time complexity of $P$ is $O(f(n))$ and that of $B$ runs in time $\omega(f(n))$.
	- The time complexity of $P$ is $o(f(n))$ and that of $B$ runs in time $\Omega(f(n))$.
