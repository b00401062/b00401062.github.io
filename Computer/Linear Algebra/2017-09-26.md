## 2017-09-26

- Solving $Ax = b$ is equivalent to solving $Lc = b$ and then $Ux = c$, where $A = LU$.
- How can we undo the steps of Gaussian elimination? By multiplying $E^{-1} (= L)$ with $Ux = c$.
- The entries below the diagonal of $L$ are the multipliers from each step of Gaussian elimination.
- __Triangular factorization__ $A = LU$ with no exchanges of rows.
    - $L$ is the __lower triangular matrix__, with 1s on the diagonal. The multipliers $l_{ij}$ (taken from elimination) are below the diagonal.
    - $U$ is the __upper triangular matrix__ which appears after forward elimination. The diagonal entries of $U$ are the _pivots_.
- The triangular factorization can be written $A = LDU$, where $L$ and $U$ have 1s on the diagonal and $D$ is the diagonal matrix of pivots.
- There is some freedom, and there is a "Crout algorithm" that arranges the calculations of $LU$ decomposition in a slightly different way. There is no freedom in the final $LDU$ decomposition.
- __Permutation matrix__: $P_{ij}$ is (1) _row exchange_ of row $i$ and row $j$, or (2) _column exchange_ of column $i$ and column $j$.
    - $PA$ performs row exchange of $A$.
    - $AP$ performs column exchange of $A$.
    - There is a single "1" in every row and column.
    - Multiplication of permutation matrices is _not_ commutative.
    - $P^{-1}$ is always the same as $P^\text{T}$.
- In the _nonsingular_ case, if there is a permutation matrix $P$ that reorders the rows of $A$ to avoid zeros in the pivot positions, then $Ax = b$ has a unique solution by solving $PAx = Pb$.
- In the _singular_ case, no $P$ can produce a full set of pivots: elimination fails.
- If $A$ is invertible, then the matrix $B$ satisfying $AB = BA = I$ is unique, and $B$ is denoted as $A^{-1}$. (Proof by contradiction)
- Not all matrices have inverses. An inverse is impossible when $Ax = 0$ and x is nonzero. (Proof by contradiction)
- A product $AB$ of invertible matrices is inverted by $B^{-1}A^{-1}$ (in reverse order).
- How to calculate $A^{-1}$? The __Gauss-Jordan method__: $[A|I] \to [U|L^{-1}] \to [I|A^{-1}]$
- A matrix is invertible iff it satisfies all the following equivalent criteria (1) independent columns/rows, (2) nonzero pivots, (3) nonzero determinant, (4) nonzero eigenvalues.
- Suppose $A$ has a full set of $n$ pivots. $AA^{-1} = I$ gives $n$ separate systems $Ax_i = e_i$ for the columns of $A^{-1}$. They can be solved by elimination or by Gauss-Jordan. Row exchanges may be needed, but the columns of $A^{-1}$ are uniquely determined.
- In general, three types of elementary matrices are allowed in Gauss-Jordan method:
    - $E_{ij}$: to subtract a multiple $l$ of row $j$ from row $i$.
    - $P_{ij}$: to exchange rows $i$ and $j$.
    - $D$: to multiply all rows by their pivots.
