## 2017-11-21

- $\{e_1,e_2,...,e_n\}$ is an orthonormal set (basis) for $\mathbb{R}^n$.
- __Orthogonal subspace__: Let $W_1$ and $W_2$ be subspaces of an inner product space $V$. $W_1$ is orthogonal to $W_2$ ($W_1\bot W_2$) if $\forall w_1\in W_1$, $\forall w_2\in W_2$, $⟨w_1,w_2⟩=0$.
- Note: In $\mathbb{R}^3$, $xy$-plane and $yz$-plane are _not_ orthogonal to each other.
- The subspace spanned by $u$ is orthogonal to the subspace spanned by $v$ if $⟨u,v⟩=0$.
- _Theorem_: Given $A_{m\times n}$. The row space is orthogonal to the nullspace in $\mathbb{R}^n$. The column space is orthogonal to the left nullspace in $\mathbb{R}^m$.
- Note: The nullspace contains every vector orthogonal to the row space.
- _Proposition_: Let $V$ be an inner product space, and $W$ be a subspace of $V$. Define $U = \{v \in V | \forall w \in W, ⟨v,w⟩=0\}$. Then, $U$ is a subspace of $V$.
- __Orthogonal complement__: The subspace $U$ is called the orthogonal complement of $W$ in $V$, denoted by $W^\bot$, if $U$ contains all vectors orthogonal to $W$.
- Examples:
    - $N(A)=C(A^\top)^\bot$: The nullspace is the orthogonal complement of the row space in $\mathbb{R}^n$.
    - $N(A^\top)=C(A)^\bot$: The left nullspace is the orthogonal complement of the column space in $\mathbb{R}^m$.
- The equation $Ax=b$ is solvable iff $b^\top y=0$ where $A^\top y=0$.
- Solvability of $Ax=b$:
    - Direct approach: $b$ must be a combination of columns of $A$.
    - Indirect approach: $b$ must be orthogonal to every vector that is orthogonal to the columns of $A$.
- $V$ and $W$ can be orthogonal without being complements.
- Splitting $\mathbb{R}^n$ into orthogonal parts will split every vector into $x = v + w$.
![image alt](https://github.com/b00401062/b00401062.github.io/raw/master/Computer/Linear%20Algebra/fig3-4.png =x200)
- The mapping from row space to column space is actually invertible. Every matrix $A$ transforms its row space to its column space.
- When $A^{-1}$ fails to exist, we can see a natural substitute, which is call __pseudoinverse__, denoted by $A^+$.
    - $\forall x \in C(A^\top), A^+Ax=x$.
    - $\forall y \in N(A^\top), A^+y=0$.
- The cosine of the angle between any two vectors $a$ & $b$ is $\cos\theta = \frac{a^\top b}{\lVert a\rVert\lVert b\rVert}$. If we consider the relationship between $\lVert a\rVert$, $\lVert b\rVert$ and $\lVert b-a\rVert$, then we have $\lVert b-a\rVert^2 = \lVert b\rVert^2 + \lVert a\rVert^2 - 2\lVert a\rVert\lVert b\rVert\cos\theta$.
- The projection of $b$ onto the line $a$ through $O$ is $p = \frac{a^\top b}{a^\top a} a$
![image alt](https://github.com/b00401062/b00401062.github.io/raw/master/Computer/Linear%20Algebra/fig3-7.png =x100)
- Any two vectors in the inner product space satisfy the __Cauchy-Shwart Inequality__: $|a^\top b|≤\lVert a\rVert\lVert b\rVert$.
    - $\lVert b-p\rVert^2 = \lVert b-\frac{a^\top b}{a^\top a} a\rVert^2 ≥ 0$. Hence, $|a^\top b|≤\lVert a\rVert\lVert b\rVert$.
    - The equality holds &hArr; $\lVert b-p\rVert^2 = 0$ &hArr; $\exists\alpha\in\mathbb{R}$, $b=p=\alpha a$.
- What is the projection matrix $P$ of the linear transformation that maps $b$ to $p$?
    - $p = \frac{a^\top b}{a^\top a} a = \frac{a a^\top}{a^\top a} b = Pb$.
    - $P = \frac{a a^\top}{a^\top a}$, which is a projection of rank one.
    - $P$ is singular and symmetric.
