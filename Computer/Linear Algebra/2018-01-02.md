## 2018-01-02

- The eigenvalues of $A^k$ are $λ_1^k,...,λ_n^k$. If $S^{-1}AS = Λ$, then $S^{-1}A^kS = Λ^k$.
- If $A$ is invertible, then the eigenvalues of $A^{-1}$ are $λ_1^{-1},...,λ_n^{-1}$.
- The eigenvectors of $A$, $A^k$, and $A^{-1}$ are identical.
- If $A$ and $B$ are diagonalizable, they have the same eigenvector matrix $S$ if and only if $AB = BA$.
    - &rArr;: Suppose there exists $S$ such that $S^{-1}AS = Λ_A$ and $S^{-1}BS = Λ_B$. $AB$ = $SΛ_AS^{-1}SΛ_BS^{-1}$ = $SΛ_AΛ_BS^{-1}$ = $SΛ_BΛ_AS^{-1}$ = $SΛ_BS^{-1}SΛ_AS^{-1}$ = $BA$.
    - &lArr;: Suppose $AB = BA$. Let $x$ be an eigenvector of $A$, i.e., $Ax = λx$. __Case 1__: $Bx = 0$. Then, $x$ is an eigenvector of $B$. __Case 2__: $Bx ≠ 0$. $ABx = BAx = λBx$. $A$ has distinct eigenvalues, each eigenspace of $A$ is one-dimensional. Hence, $Bx = µx$ for some scalar $µ$, i.e., $Bx$ is a multiple of $x$. In other words, $x$ is an eigenvector of $B$ as well.
- __Theorem__: $AB$ and $BA$ have the same eigenvalues.
- __Theorem__: Let $A$ be an $n×n$ matrix over $F$. Assume that the characteristic polynomial of $A$ has solutions in $F$. Then, for each eigenvalue of $A$, geometric multiplicity ≤ algebraic multiplicity.
- __Recurrence relation (Difference equation)__: Using Fibonacci sequence as an example: $a_{k+2} = a_{k+1} + a_k$, where $a_0 = 0$, $a_1 = 1$.
    - Let $u_k = (a_{k+1}, a_k)$. We have $u_0 = (1,0)$ and $u_k$ = $\begin{bmatrix} 1 & 1 \\ 1 & 0 \end{bmatrix} u_{k-1}$.
    - Let $A = \begin{bmatrix} 1 & 1 \\ 1 & 0 \end{bmatrix}$. We have $u_k$ = $A^k u_0$ = $SΛ^kS^{-1}u_0$ = $SΛ^kc$ where $c = S^{-1}u_0$.
- __Markov chain__:
    - __Transition matrix (Markov matrix)__: a square matrix used to describe the transitions of a Markov chain.
    - Essential assumptions:
        - The total # of instances stays fixed, i.e., columns sum to 1.
        - The number of instances is never negative, i.e., all entries are non-negative.
        - Current state depends only on the last state, i.e., $u_k$ depends only on $u_{k-1}$ (no history).
    - Let $u_k$ be the distribution of instances at time $k$. We have $u_k = Au_{k-1}$ and $u_k$ = $A^k u_0$ = $SΛ^kS^{-1}u_0$ = $SΛ^kc$ where $c = S^{-1}u_0$.
    - Eigenvectors of a transition matrix $A$ are $λ_1=1,λ_2,...,λ_n$ which satisfies $1>λ_2≥...≥λ_n>0$.
    - No matter what the initial distribution may have been, the steady state $u_∞$ satisfies $u_∞ = Au_∞$, i.e., $u_∞$ is the eigenvector corresponding to $λ = 1$.
- The __conjugate transpose__ of a matrix $A$ is denoted by $A^\text{H}$ (= $\overline{A^\top}$). __Note__: $(AB)^\text{H} = B^\text{H}A^\text{H}$.
- For $x\in\mathbb{C}^n$, the length of $x$, i.e., $‖x‖$, is defined as $‖x‖^2 = |x_1|^2 + ... + |x_n|^2$ = $x^\text{H}x$ = $\overline{x}^\top x$.
- The inner product of complex vector $⟨x,y⟩$ = $x^\text{H}y$ = $\overline{x}^\top y$ = $y^\top\overline{x}$. __Note__: (1) $⟨x,y⟩$ = $\overline{⟨y,x⟩}$; (2) $⟨cx,y⟩$ = $c⟨x,y⟩$; (3) $⟨x,cy⟩$ = $\overline{c}⟨x,y⟩$.
- $x$ is orthogonal to $y$ if $x^\text{H}y = 0$.
- An $n\times n$ matrix $A$ is called a __Hermitian matrix__ if and only if $A^\text{H} = A$.
- If $A^\text{H} = A$, then $x^\text{H}Ax$ is real for all $x\in\mathbb{C}^n$.
    - $(x^\text{H}Ax)^\text{H}$ = $x^\text{H}A^\text{H}x$ = $x^\text{H}Ax$.
- Every eigenvalue of a Hermitian matrix is real.
    - Let $λ$ be an eigenvalue of $A$ and $A^\text{H}=A$.
    - There exists $x ≠ 0$ such that $Ax=λx$.
    - $x^\text{H}Ax$ = $λx^\text{H}x$ &rArr; $λ = x^\text{H}Ax / x^\text{H}x$, which is a real number.
- The eigenvectors corresponding to distinct eigenvalues of a Hermitian matrix are orthogonal to each other.
    - Suppose $A^\text{H} = A$ and $Ax_1 = λ_1x_1$, $Ax_2 = λ_2x_2$, where $λ_1 ≠ λ_2$, $x ≠ 0$, $y ≠ 0$.
    - $λ_1x_1^\text{H}x_2$ = $(λ_1x_1)^\text{H}x_2$ = $(Ax_1)^\text{H}x_2$ = $x_1^\text{H}A^\text{H}x_2$ = $x_1^\text{H}Ax_2$ = $x_1^\text{H}(Ax_2)$ = $x_1^\text{H}(λ_2x_2)$ = $λ_2x_1^\text{H}x_2$.
    - $(λ_1-λ_2)x_1^\text{H}x_2$ = 0 and $λ_1≠λ_2$. Hence, $x_1^\text{H}x_2$ = 0, i.e., eigenvectors are orthogonal.
